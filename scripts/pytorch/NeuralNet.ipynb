{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Neural Networks\n",
    "\n",
    "Remember to change the `ver` variable prior to running!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/chetai/Desktop/pytorch/')\n",
    "\n",
    "import pdb\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Neural network structure imports\n",
    "from GCN.GCN import GCN\n",
    "# from GAT.GAT import GAT\n",
    "from Dense.Dense import Dense\n",
    "\n",
    "# Processing imports\n",
    "from sub_data_process import SubGraphProcess\n",
    "from full_data_process import GraphDataProcess\n",
    "\n",
    "# Utility imports\n",
    "from utils.utils import *\n",
    "from utils.label_functions import *\n",
    "from utils.feature_functions import *\n",
    "from utils.adjacency_functions import *\n",
    "from utils.train_test_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_graph_process(param_dict, full_processed_path, full_redo):\n",
    "    \"\"\"\n",
    "    Wrapper for processing data on the full mined data-set\n",
    "    \n",
    "    Input(s):\n",
    "    - param_dict (dict)\n",
    "    - full_processed_path (string): Save path for processed version of full data\n",
    "    - full_redo (bool): Whether or not to re-compute \n",
    "    \n",
    "    Output(s):\n",
    "    GraphDataProcess object \n",
    "    \"\"\"\n",
    "    if (not os.path.exists(full_processed_path)) or full_redo:\n",
    "        # Parse path to mined data\n",
    "        raw_data_path = param_dict['gen_params']['raw_data_path']\n",
    "        \n",
    "        # Parse save directory and names of intermediate files\n",
    "        data_dir = param_dict['gen_params']['data_dir']\n",
    "        full_names_dict = param_dict['full_names_dict']\n",
    "        \n",
    "        # Parse flags of redoing calculation\n",
    "        full_redo_dict = param_dict['full_redo_dict']\n",
    "        \n",
    "        # Get processing object and execute\n",
    "        graph_data_obj = GraphDataProcess(raw_data_path, data_dir, full_names_dict, full_redo_dict)\n",
    "        graph_data_obj.run_all()\n",
    "        \n",
    "        save_pickle(graph_data_obj, full_processed_path)\n",
    "    else:\n",
    "        graph_data_obj = load_pickle(full_processed_path)\n",
    "    \n",
    "    return graph_data_obj\n",
    "\n",
    "\n",
    "def sub_graph_process(param_dict, data_path, full_processed_path, sub_processed_path, sub_redo):\n",
    "    \"\"\"\n",
    "    Wrapper for sampling data subset and organizing model input features\n",
    "    \n",
    "    Input(s):\n",
    "    - param_dict (dict)\n",
    "    - data_path (string): Path to intermediate save files (for sub-sampling)\n",
    "    - full_processed_path (string): Path to access full processed data\n",
    "    - sub_processed_path (string): Path to save or load sub-processed object\n",
    "    - sub_redo (bool): Whether or not to re-compute \n",
    "    \"\"\"\n",
    "    if (not os.path.exists(sub_processed_path)) or sub_redo:\n",
    "        # Parse parameters\n",
    "        sampling_params = param_dict['sampling_params']\n",
    "        sub_names_dict = param_dict['sub_names_dict']\n",
    "        sub_redo_dict = param_dict['sub_redo_dict']\n",
    "        \n",
    "        # Dictionary of processing functions\n",
    "        sub_functions_dict = get_func_dict(param_dict['sub_functions_dict'])\n",
    "        \n",
    "        # Get sampling object and execute\n",
    "        subgraph_data_obj = SubGraphProcess(\n",
    "            full_processed_path, \n",
    "            data_path, \n",
    "            sub_names_dict, \n",
    "            sub_redo_dict, \n",
    "            sub_functions_dict, \n",
    "            sampling_params\n",
    "        )\n",
    "        subgraph_data_obj.run_all()\n",
    "        \n",
    "        save_pickle(subgraph_data_obj, sub_processed_path)\n",
    "    else:\n",
    "        subgraph_data_obj = load_pickle(sub_processed_path)\n",
    "        \n",
    "    return subgraph_data_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unwrap and Set General Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parameters\n",
    "ver = 'dense'\n",
    "param_path = 'C:/Users/chetai/Desktop/' + ver + '/params.json'\n",
    "param_dict = json.load(open(param_path,'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing model type and version\n",
    "model_type = param_dict['gen_params']['model_type']\n",
    "ver = param_dict['gen_params']['ver']\n",
    "\n",
    "# Parsing save directories\n",
    "data_dir = param_dict['gen_params']['data_dir']\n",
    "result_dir = param_dict['gen_params']['result_dir']\n",
    "\n",
    "# Create descriptive save paths\n",
    "data_path, result_path = set_paths(model_type, ver, data_dir, result_dir)\n",
    "\n",
    "# Parse processed result names and create paths\n",
    "full_processed_name = param_dict['gen_params']['full_processed_name']\n",
    "sub_processed_name = param_dict['gen_params']['sub_processed_name']\n",
    "\n",
    "full_processed_path = data_dir + full_processed_name\n",
    "sub_processed_path = data_path + sub_processed_name\n",
    "\n",
    "# Parse redo settings\n",
    "full_redo = param_dict['gen_params']['full_redo']\n",
    "sub_redo = param_dict['gen_params']['sub_redo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get full processed data\n",
    "graph_data_obj = full_graph_process(param_dict, full_processed_path, full_redo)\n",
    "\n",
    "# Get sampled processed data\n",
    "subgraph_data_obj = sub_graph_process(param_dict, data_path, full_processed_path, sub_processed_path, sub_redo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse split ratio dictionary\n",
    "split_ratio_dict = param_dict['split_ratio_dict']\n",
    "\n",
    "# Set binary vs. multi-class classification \n",
    "target_grade = -1\n",
    "\n",
    "# Get data for PyTorch training\n",
    "features, adj, labels, idx_train, idx_dev, idx_test = sample_and_load_pytorch_data(\n",
    "    subgraph_data_obj, \n",
    "    split_ratio_dict, \n",
    "    result_path, \n",
    "    target_grade, \n",
    "    sub_redo\n",
    ")\n",
    "\n",
    "# Set number of labels\n",
    "num_labels = len(list(set(list(np.asarray(labels)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train-dev-test indexes\n",
    "idx_train_path = data_path + 'train_idxs.pickle'\n",
    "idx_dev_path = data_path + 'dev_idxs.pickle'\n",
    "idx_test_path = data_path + 'test_idxs.pickle'\n",
    "\n",
    "save_pickle(idx_train.numpy(), idx_train_path)\n",
    "save_pickle(idx_dev.numpy(), idx_dev_path)\n",
    "save_pickle(idx_test.numpy(), idx_test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Neural Network Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_params = param_dict['dense_params']\n",
    "if dense_params['on']:\n",
    "    num_epochs = dense_params['num_epochs']\n",
    "    model = Dense(\n",
    "        nfeatures=features.shape[1],\n",
    "        nhidden_layer_list=dense_params['hidden'],\n",
    "        nclass=num_labels,\n",
    "        dropout=dense_params['dropout']\n",
    "    )\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=dense_params['lr'], \n",
    "        weight_decay=dense_params['weight_decay']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_params = param_dict['gcn_params']\n",
    "if gcn_params['on']:\n",
    "    num_epochs = gcn_params['num_epochs']\n",
    "    model = GCN(\n",
    "        nfeatures=features.shape[1],\n",
    "        nhidden_layer_list=gcn_params['hidden'],\n",
    "        nclass=num_labels,\n",
    "        dropout=gcn_params['dropout']\n",
    "    )\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=gcn_params['lr'], \n",
    "        weight_decay=gcn_params['weight_decay']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "train_dict = {}\n",
    "train_dict['optimizer'] = optimizer\n",
    "train_dict['features'] = features\n",
    "train_dict['adj'] = adj\n",
    "train_dict['labels'] = labels\n",
    "train_dict['idx_train'] = idx_train\n",
    "train_dict['idx_val'] = idx_dev\n",
    "train_dict['num_epochs'] = num_epochs\n",
    "\n",
    "model = run_train(model, train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "test_dict = {}\n",
    "test_dict['features'] = features\n",
    "test_dict['adj'] = adj\n",
    "test_dict['labels'] = labels\n",
    "test_dict['idx_test'] = idx_test\n",
    "\n",
    "test(model, test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_name = 'model.pickle'\n",
    "save_pickle(model, result_path + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
