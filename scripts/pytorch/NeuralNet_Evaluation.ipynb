{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Neural Net Predictions\n",
    "\n",
    "Remember to change the `model_type` and `ver` variables prior to running!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/chetai/Documents/Projects/moonGen/')\n",
    "\n",
    "import os\n",
    "import pdb\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from scripts.evaluation.eval_utils import *\n",
    "from scripts.evaluation.evaluation_tools import *\n",
    "from scripts.pytorch.utils.train_test_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Experiment Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify experiment settings\n",
    "model_type = 'GCN'\n",
    "ver = 'v0'\n",
    "\n",
    "data_dir = 'C:/Users/chetai/Desktop/moonboard_data/'\n",
    "result_dir = 'C:/Users/chetai/Desktop/moonboard_results/'\n",
    "\n",
    "subpath_suffix = '%s/%s/' % (model_type, ver)\n",
    "data_path = data_dir + subpath_suffix\n",
    "result_path = result_dir + subpath_suffix\n",
    "\n",
    "# Load experiment parameters\n",
    "with open(data_path + 'params.json', 'r') as f:\n",
    "    param_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to model outputs\n",
    "model_path = result_path + 'model.pickle'\n",
    "features_path = result_path + 'features.pickle'\n",
    "adj_path = result_path + 'adj.pickle'\n",
    "labels_path = result_path + 'labels.pickle'\n",
    "idx_train_path = result_path + 'idx_train.pickle'\n",
    "idx_val_path = result_path + 'idx_dev.pickle'\n",
    "idx_test_path = result_path + 'idx_test.pickle'\n",
    "\n",
    "# Load model outputs\n",
    "model = load_pickle(model_path)\n",
    "features = load_pickle(features_path)\n",
    "adj = load_pickle(adj_path)\n",
    "labels = load_pickle(labels_path)\n",
    "idx_train = load_pickle(idx_train_path)\n",
    "idx_val = load_pickle(idx_val_path)\n",
    "idx_test = load_pickle(idx_test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get accuracy on test set\n",
    "test_dict = dict()\n",
    "test_dict['features'] = features\n",
    "test_dict['adj'] = adj\n",
    "test_dict['labels'] = labels\n",
    "test_dict['idx_test'] = idx_test\n",
    "\n",
    "test(model, test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass on network\n",
    "output = model(features, adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test predictions\n",
    "Y_pred_test = np.exp(output[idx_test].detach().numpy())[:, 1:]  # Drop 0 class (holds)\n",
    "Y_label_test = onehot_labels(labels.numpy()[idx_test] - 1, Y_pred_test.shape[1])  # Shift labels by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train predictions\n",
    "Y_pred_train = np.exp(output[idx_train].detach().numpy())[:, 1:]  \n",
    "Y_label_train = onehot_labels(labels.numpy()[idx_train] - 1, Y_pred_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Evaluation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_out_root = result_path + 'train/'\n",
    "tst_out_root = result_path + 'test/'\n",
    "\n",
    "make_directory(trn_out_root)\n",
    "make_directory(tst_out_root)\n",
    "    \n",
    "trn_settings = {\n",
    "    'description': 'Train Debug',\n",
    "    'corr_fig_save': trn_out_root + 'fig_correlation.png',\n",
    "    'farp_fig_save': trn_out_root + 'fig_farpa.png',\n",
    "    'farp_stats_save': trn_out_root + 'stats_farpa.pickle',\n",
    "    'confusion_fig_save': trn_out_root + 'fig_confusion.png',\n",
    "    'global_stats_save': trn_out_root + 'stats_global.pickle'\n",
    "}\n",
    "\n",
    "tst_settings = {\n",
    "    'description': 'Test Debug',\n",
    "    'corr_fig_save': tst_out_root + 'fig_correlation.png',\n",
    "    'farp_fig_save': tst_out_root + 'fig_farpa.png',\n",
    "    'farp_stats_save': tst_out_root + 'stats_farpa.pickle',\n",
    "    'confusion_fig_save': tst_out_root + 'fig_confusion.png',\n",
    "    'global_stats_save': tst_out_root + 'stats_global.pickle'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate_predictions(Y_label_train, Y_pred_train, trn_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate_predictions(Y_label_test, Y_pred_test, tst_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
